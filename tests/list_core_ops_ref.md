# Core ATen ops support (codegen backend)

This list shows core ATen operators, whether the codegen backend supports them, and how many OpInfo sample inputs exist for the first CPU dtype.

| aten op | codegen support | opinfo test cases |
| --- | --- | --- |
| `_adaptive_avg_pool2d` | ✅ | — |
| `_adaptive_avg_pool2d_backward` | ✅ | — |
| `_adaptive_avg_pool3d` | ✅ | — |
| `_cdist_forward` | ✅ | — |
| `_embedding_bag` | ✅ | — |
| `_fft_r2c` | — | — |
| `_local_scalar_dense` | ✅ | — |
| `_log_softmax` | ✅ | — |
| `_native_batch_norm_legit` | ✅ | 10 |
| `_native_batch_norm_legit.no_stats` | — | — |
| `_native_batch_norm_legit_no_training` | ✅ | — |
| `_pdist_forward` | ✅ | — |
| `_softmax` | ✅ | — |
| `_to_copy` | ✅ | — |
| `abs` | ✅ | 1 |
| `acos` | ✅ | 3 |
| `acosh` | ✅ | 3 |
| `adaptive_avg_pool1d` | ✅ | — |
| `add.Scalar` | ✅ | — |
| `add.Tensor` | ✅ | — |
| `addmm` | ✅ | 6 |
| `alias` | ✅ | — |
| `amax` | ✅ | 20 |
| `amin` | ✅ | 20 |
| `any` | ✅ | 20 |
| `any.dim` | ✅ | — |
| `any.dims` | ✅ | — |
| `arange.start_step` | ✅ | — |
| `argmax` | ✅ | 13 |
| `argmin` | ✅ | 13 |
| `as_strided` | ✅ | 5 |
| `asin` | ✅ | 1 |
| `asinh` | ✅ | 1 |
| `atan` | ✅ | 1 |
| `atan2` | ✅ | 9 |
| `atan2.out` | ✅ | — |
| `atanh` | ✅ | 1 |
| `avg_pool1d` | ✅ | 9 |
| `avg_pool2d` | ✅ | 7 |
| `avg_pool2d_backward` | ✅ | — |
| `avg_pool3d` | ✅ | 8 |
| `bitwise_and.Scalar` | ✅ | — |
| `bitwise_and.Tensor` | ✅ | — |
| `bitwise_not` | ✅ | 3 |
| `bitwise_or.Scalar` | ✅ | — |
| `bitwise_or.Tensor` | ✅ | — |
| `bitwise_xor.Scalar` | ✅ | — |
| `bitwise_xor.Tensor` | ✅ | — |
| `bmm` | ✅ | 1 |
| `cat` | ✅ | 9 |
| `ceil` | ✅ | 1 |
| `clamp` | ✅ | 7 |
| `clamp.Tensor` | ✅ | — |
| `clone` | ✅ | 2 |
| `col2im` | ✅ | — |
| `constant_pad_nd` | ✅ | 49 |
| `convolution` | ✅ | — |
| `convolution_backward` | — | — |
| `copy` | ✅ | — |
| `cos` | ✅ | 3 |
| `cosh` | ✅ | 3 |
| `cumsum` | ✅ | 4 |
| `diagonal` | ✅ | 15 |
| `div.Scalar` | ✅ | — |
| `div.Scalar_mode` | ✅ | — |
| `div.Tensor` | ✅ | — |
| `div.Tensor_mode` | ✅ | — |
| `elu` | ✅ | — |
| `embedding` | ✅ | — |
| `embedding_dense_backward` | ✅ | — |
| `empty.memory_format` | — | — |
| `empty_strided` | ✅ | 4 |
| `eq.Scalar` | ✅ | — |
| `eq.Tensor` | ✅ | — |
| `erf` | ✅ | 1 |
| `exp` | ✅ | 3 |
| `expand` | ✅ | 9 |
| `expm1` | ✅ | 1 |
| `fill.Scalar` | ✅ | — |
| `flip` | ✅ | 10 |
| `floor` | ✅ | 1 |
| `fmod.Scalar` | ✅ | — |
| `fmod.Tensor` | ✅ | — |
| `full` | — | 4 |
| `full_like` | ✅ | 7 |
| `gather` | ✅ | 7 |
| `ge.Scalar` | ✅ | — |
| `ge.Tensor` | ✅ | — |
| `gelu` | ✅ | 8 |
| `grid_sampler_2d` | — | 18 |
| `gt.Scalar` | ✅ | — |
| `gt.Tensor` | ✅ | — |
| `hardtanh` | ✅ | 5 |
| `index.Tensor` | — | — |
| `index_put` | ✅ | 4 |
| `index_select` | ✅ | 3 |
| `isinf` | ✅ | 1 |
| `isnan` | ✅ | 1 |
| `le.Scalar` | ✅ | — |
| `le.Tensor` | ✅ | — |
| `leaky_relu` | ✅ | 9 |
| `log` | ✅ | 3 |
| `log10` | ✅ | 3 |
| `log1p` | ✅ | 1 |
| `log2` | ✅ | 3 |
| `logical_and` | ✅ | 9 |
| `logical_not` | ✅ | 3 |
| `logical_or` | ✅ | 9 |
| `logical_xor` | ✅ | 9 |
| `lt.Scalar` | ✅ | — |
| `lt.Tensor` | ✅ | — |
| `masked_scatter` | ✅ | 4 |
| `max.dim` | ✅ | — |
| `max_pool2d_with_indices` | — | — |
| `max_pool2d_with_indices_backward` | ✅ | 1440 |
| `max_pool3d_with_indices` | ✅ | — |
| `maximum` | ✅ | 9 |
| `mean` | ✅ | 20 |
| `mean.dim` | ✅ | — |
| `min.dim` | ✅ | — |
| `minimum` | ✅ | 9 |
| `mm` | ✅ | 3 |
| `mul.Scalar` | ✅ | — |
| `mul.Tensor` | ✅ | — |
| `native_dropout` | ✅ | — |
| `native_group_norm` | ✅ | — |
| `native_group_norm_backward` | ✅ | — |
| `native_layer_norm` | ✅ | 20 |
| `native_layer_norm_backward` | ✅ | — |
| `ne.Scalar` | ✅ | — |
| `ne.Tensor` | ✅ | — |
| `neg` | ✅ | 1 |
| `nonzero` | ✅ | 24 |
| `permute` | ✅ | 4 |
| `pow.Scalar` | ✅ | — |
| `pow.Tensor_Scalar` | ✅ | — |
| `pow.Tensor_Tensor` | ✅ | — |
| `prod` | ✅ | 39 |
| `prod.dim_int` | ✅ | — |
| `rand` | ✅ | — |
| `randn` | ✅ | 2 |
| `randperm` | ✅ | — |
| `reciprocal` | ✅ | 3 |
| `reflection_pad1d` | ✅ | — |
| `reflection_pad2d` | ✅ | — |
| `reflection_pad3d` | ✅ | — |
| `relu` | ✅ | 4 |
| `remainder.Scalar` | ✅ | — |
| `remainder.Tensor` | ✅ | — |
| `repeat` | ✅ | 40 |
| `replication_pad2d` | ✅ | — |
| `replication_pad3d` | ✅ | — |
| `resize_` | ✅ | 3 |
| `round` | ✅ | 1 |
| `rsqrt` | ✅ | 3 |
| `scalar_tensor` | ✅ | 3 |
| `scatter.src` | ✅ | — |
| `scatter.value` | ✅ | — |
| `scatter_add` | — | 7 |
| `scatter_reduce.two` | — | — |
| `select.int` | ✅ | — |
| `select_scatter` | ✅ | 5 |
| `sigmoid` | ✅ | 3 |
| `sign` | ✅ | 1 |
| `sin` | ✅ | 1 |
| `sinh` | ✅ | 1 |
| `slice.Tensor` | ✅ | — |
| `slice_scatter` | — | 9 |
| `sort` | ✅ | 58 |
| `split_with_sizes` | ✅ | 4 |
| `sqrt` | ✅ | 1 |
| `squeeze.dim` | ✅ | — |
| `squeeze.dims` | ✅ | — |
| `sub.Scalar` | ✅ | — |
| `sub.Tensor` | ✅ | — |
| `sum.dim_IntList` | ✅ | — |
| `sym_is_contiguous` | — | — |
| `sym_numel` | — | — |
| `sym_size.int` | — | — |
| `sym_storage_offset` | — | — |
| `sym_stride.int` | — | — |
| `tan` | ✅ | 1 |
| `tanh` | ✅ | 1 |
| `topk` | — | 14 |
| `trunc` | ✅ | 1 |
| `unsqueeze` | ✅ | 9 |
| `upsample_bilinear2d.vec` | — | — |
| `upsample_nearest2d.vec` | — | — |
| `var.correction` | — | — |
| `var.dim` | ✅ | — |
| `view` | ✅ | 7 |
| `where.self` | ✅ | — |

## Summary
- total core aten ops: 192
- supported by codegen: 172 / 192 (89.6%)
- unsupported by codegen: 20
