/*
 * Generated by emx-pytorch2c export_generic_c.
 * Options:
 *   function_name: 'entry'
 *   truncate_weights_after: 10
 *   temp_allocation_threshold: 1024
 *   variable_dim_inputs: {}
 *   variable_dim_outputs: {}
 */
#include <stdint.h>
#include <sys/types.h>
#include <stdbool.h>
#include <float.h>
#include <math.h>
static const float weight_initializer_b[4] = {
    0x1.4ccccdp-4f, -0x1.4ccccdp-3f, 0x1.19999ap-2f, 0x0.0p+0f
};

#ifndef REF_PI_F
#define REF_PI_F 3.14159265358979323846f
#endif
#ifndef REF_PI_D
#define REF_PI_D 3.14159265358979323846
#endif

static inline float ref_scalar_f32_add(float a, float b) {
    return a + b;
}

/*
* op: add (kind: binary)
* inputs: [shape=(1, 4), size=4, shape=(4,), size=4]
* output: shape=(1, 4), size=4
* params: {}
*/
void node1_add_f32(const float a[1][4], const float b[4], float out[1][4]) {
    for (ssize_t i0 = 0; i0 < 1; ++i0) {
        for (ssize_t i1 = 0; i1 < 4; ++i1) {
            out[i0][i1] = ref_scalar_f32_add(a[0][i1], b[i1]);
        }
    }
}

void ref_codegen_main_f32(const float input_0[1][4], const float input_1[4], float out[1][4]) {
    node1_add_f32(input_0, input_1, out);
}

void entry(const float in0[1][4], float out0[1][4]) {
    ref_codegen_main_f32(in0, weight_initializer_b, out0);
}
