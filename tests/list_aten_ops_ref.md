# All ATen ops support (codegen backend)

This list shows all ATen operators, whether the codegen backend supports them, and how many OpInfo sample inputs exist for the first CPU dtype.

| aten op | codegen support | opinfo test cases |
| --- | --- | --- |
| `Bool` | — | — |
| `Complex` | — | — |
| `Delete` | — | — |
| `Float` | — | — |
| `Generator` | — | — |
| `Int` | — | — |
| `Size` | — | — |
| `__and__` | — | — |
| `__contains__` | — | — |
| `__derive_index` | — | — |
| `__getitem__` | — | 16 |
| `__iand__` | — | — |
| `__ilshift__` | — | — |
| `__interpolate` | — | — |
| `__ior__` | — | — |
| `__irshift__` | — | — |
| `__is__` | — | — |
| `__isnot__` | — | — |
| `__ixor__` | — | — |
| `__lshift__` | — | — |
| `__not__` | — | — |
| `__or__` | — | — |
| `__range_length` | — | — |
| `__round_to_zero_floordiv` | — | — |
| `__rshift__` | — | — |
| `__upsample` | — | — |
| `__upsample_bilinear` | — | — |
| `__upsample_nearest` | — | — |
| `__xor__` | — | — |
| `_adaptive_avg_pool2d` | ✅ | — |
| `_adaptive_avg_pool2d_backward` | ✅ | — |
| `_adaptive_avg_pool3d` | ✅ | — |
| `_adaptive_avg_pool3d_backward` | — | — |
| `_add_batch_dim` | — | — |
| `_add_relu` | — | — |
| `_add_relu_` | — | — |
| `_addmm_activation` | — | — |
| `_aminmax` | — | — |
| `_amp_foreach_non_finite_check_and_unscale` | — | — |
| `_amp_foreach_non_finite_check_and_unscale_` | — | — |
| `_amp_update_scale` | — | — |
| `_amp_update_scale_` | — | — |
| `_assert_async` | — | — |
| `_assert_scalar` | — | — |
| `_assert_tensor_metadata` | — | — |
| `_autocast_to_full_precision` | — | — |
| `_autocast_to_reduced_precision` | — | — |
| `_backward` | — | — |
| `_batch_norm_impl_index` | — | — |
| `_batch_norm_impl_index_backward` | — | — |
| `_batch_norm_no_update` | — | — |
| `_batch_norm_with_update` | — | 9 |
| `_batch_norm_with_update_functional` | — | — |
| `_cast_Byte` | — | — |
| `_cast_Char` | — | — |
| `_cast_Double` | — | — |
| `_cast_Float` | — | — |
| `_cast_Half` | — | — |
| `_cast_Int` | — | — |
| `_cast_Long` | — | — |
| `_cast_Short` | — | — |
| `_cdist_backward` | — | — |
| `_cdist_forward` | ✅ | — |
| `_cholesky_solve_helper` | — | — |
| `_choose_qparams_per_tensor` | — | — |
| `_chunk_cat` | — | 8 |
| `_coalesce` | — | — |
| `_coalesced` | — | — |
| `_coalesced_` | — | — |
| `_compute_linear_combination` | — | — |
| `_conj` | — | — |
| `_conj_copy` | — | — |
| `_conj_physical` | — | — |
| `_conv_depthwise2d` | — | — |
| `_convert_indices_from_coo_to_csr` | — | — |
| `_convert_indices_from_csr_to_coo` | — | — |
| `_convert_weight_to_int4pack` | — | — |
| `_convert_weight_to_int4pack_for_cpu` | — | — |
| `_convolution` | — | — |
| `_convolution_double_backward` | — | — |
| `_convolution_mode` | — | — |
| `_copy_from` | — | — |
| `_copy_from_and_resize` | — | — |
| `_cslt_compress` | — | — |
| `_cslt_sparse_mm` | — | — |
| `_cslt_sparse_mm_search` | — | — |
| `_ctc_loss` | — | — |
| `_ctc_loss_backward` | — | — |
| `_cudnn_attention_backward` | — | — |
| `_cudnn_attention_forward` | — | — |
| `_cudnn_ctc_loss` | — | — |
| `_cudnn_init_dropout_state` | — | — |
| `_cudnn_rnn` | — | — |
| `_cudnn_rnn_backward` | — | — |
| `_cudnn_rnn_flatten_weight` | — | — |
| `_cufft_clear_plan_cache` | — | — |
| `_cufft_get_plan_cache_max_size` | — | — |
| `_cufft_get_plan_cache_size` | — | — |
| `_cufft_set_plan_cache_max_size` | — | — |
| `_cummax_helper` | — | — |
| `_cummin_helper` | — | — |
| `_debug_has_internal_overlap` | — | — |
| `_dimI` | — | — |
| `_dimV` | — | — |
| `_dim_arange` | — | — |
| `_dirichlet_grad` | — | — |
| `_dyn_quant_matmul_4bit` | — | — |
| `_dyn_quant_pack_4bit_weight` | — | — |
| `_efficient_attention_backward` | — | — |
| `_efficient_attention_forward` | — | — |
| `_efficientzerotensor` | — | — |
| `_embedding_bag` | ✅ | — |
| `_embedding_bag_backward` | — | — |
| `_embedding_bag_dense_backward` | — | — |
| `_embedding_bag_forward_only` | — | — |
| `_embedding_bag_per_sample_weights_backward` | — | — |
| `_embedding_bag_sparse_backward` | — | — |
| `_empty_affine_quantized` | — | — |
| `_empty_per_channel_affine_quantized` | — | — |
| `_euclidean_dist` | — | — |
| `_fake_quantize_learnable_per_channel_affine` | — | — |
| `_fake_quantize_learnable_per_channel_affine_backward` | — | — |
| `_fake_quantize_learnable_per_tensor_affine` | — | — |
| `_fake_quantize_learnable_per_tensor_affine_backward` | — | — |
| `_fake_quantize_per_tensor_affine_cachemask_tensor_qparams` | — | — |
| `_fft_c2c` | — | — |
| `_fft_c2r` | — | — |
| `_fft_r2c` | — | — |
| `_fill_mem_eff_dropout_mask_` | — | — |
| `_flash_attention_backward` | — | — |
| `_flash_attention_forward` | — | — |
| `_foobar` | — | — |
| `_foreach_abs` | — | — |
| `_foreach_abs_` | — | — |
| `_foreach_acos` | — | — |
| `_foreach_acos_` | — | — |
| `_foreach_add` | — | — |
| `_foreach_add_` | — | — |
| `_foreach_addcdiv` | — | — |
| `_foreach_addcdiv_` | — | — |
| `_foreach_addcmul` | — | — |
| `_foreach_addcmul_` | — | — |
| `_foreach_asin` | — | — |
| `_foreach_asin_` | — | — |
| `_foreach_atan` | — | — |
| `_foreach_atan_` | — | — |
| `_foreach_ceil` | — | — |
| `_foreach_ceil_` | — | — |
| `_foreach_clamp_max` | — | — |
| `_foreach_clamp_max_` | — | — |
| `_foreach_clamp_min` | — | — |
| `_foreach_clamp_min_` | — | — |
| `_foreach_copy` | — | — |
| `_foreach_copy_` | — | — |
| `_foreach_cos` | — | — |
| `_foreach_cos_` | — | — |
| `_foreach_cosh` | — | — |
| `_foreach_cosh_` | — | — |
| `_foreach_div` | — | — |
| `_foreach_div_` | — | — |
| `_foreach_erf` | — | — |
| `_foreach_erf_` | — | — |
| `_foreach_erfc` | — | — |
| `_foreach_erfc_` | — | — |
| `_foreach_exp` | — | — |
| `_foreach_exp_` | — | — |
| `_foreach_expm1` | — | — |
| `_foreach_expm1_` | — | — |
| `_foreach_floor` | — | — |
| `_foreach_floor_` | — | — |
| `_foreach_frac` | — | — |
| `_foreach_frac_` | — | — |
| `_foreach_lerp` | — | — |
| `_foreach_lerp_` | — | — |
| `_foreach_lgamma` | — | — |
| `_foreach_lgamma_` | — | — |
| `_foreach_log` | — | — |
| `_foreach_log10` | — | — |
| `_foreach_log10_` | — | — |
| `_foreach_log1p` | — | — |
| `_foreach_log1p_` | — | — |
| `_foreach_log2` | — | — |
| `_foreach_log2_` | — | — |
| `_foreach_log_` | — | — |
| `_foreach_max` | — | — |
| `_foreach_maximum` | — | — |
| `_foreach_maximum_` | — | — |
| `_foreach_minimum` | — | — |
| `_foreach_minimum_` | — | — |
| `_foreach_mul` | — | — |
| `_foreach_mul_` | — | — |
| `_foreach_neg` | — | — |
| `_foreach_neg_` | — | — |
| `_foreach_norm` | — | — |
| `_foreach_pow` | — | — |
| `_foreach_pow_` | — | — |
| `_foreach_reciprocal` | — | — |
| `_foreach_reciprocal_` | — | — |
| `_foreach_round` | — | — |
| `_foreach_round_` | — | — |
| `_foreach_rsqrt` | — | — |
| `_foreach_rsqrt_` | — | — |
| `_foreach_sigmoid` | — | — |
| `_foreach_sigmoid_` | — | — |
| `_foreach_sign` | — | — |
| `_foreach_sign_` | — | — |
| `_foreach_sin` | — | — |
| `_foreach_sin_` | — | — |
| `_foreach_sinh` | — | — |
| `_foreach_sinh_` | — | — |
| `_foreach_sqrt` | — | — |
| `_foreach_sqrt_` | — | — |
| `_foreach_sub` | — | — |
| `_foreach_sub_` | — | — |
| `_foreach_tan` | — | — |
| `_foreach_tan_` | — | — |
| `_foreach_tanh` | — | — |
| `_foreach_tanh_` | — | — |
| `_foreach_trunc` | — | — |
| `_foreach_trunc_` | — | — |
| `_foreach_zero` | — | — |
| `_foreach_zero_` | — | — |
| `_functional_assert_async` | — | — |
| `_functional_assert_scalar` | — | — |
| `_functional_sym_constrain_range` | — | — |
| `_functional_sym_constrain_range_for_size` | — | — |
| `_fused_adagrad` | — | — |
| `_fused_adagrad_` | — | — |
| `_fused_adam` | — | — |
| `_fused_adam_` | — | — |
| `_fused_adamw` | — | — |
| `_fused_adamw_` | — | — |
| `_fused_dropout` | — | — |
| `_fused_moving_avg_obs_fq_helper` | — | — |
| `_fused_moving_avg_obs_fq_helper_functional` | — | — |
| `_fused_rms_norm` | — | — |
| `_fused_rms_norm_backward` | — | — |
| `_fused_sdp_choice` | — | — |
| `_fused_sgd` | — | — |
| `_fused_sgd_` | — | — |
| `_fw_primal` | — | — |
| `_fw_primal_copy` | — | — |
| `_gather_sparse_backward` | — | — |
| `_get_cpu_capability` | — | — |
| `_get_tracing_state` | — | — |
| `_grad_sum_to_size` | — | — |
| `_grid_sampler_2d_cpu_fallback` | — | — |
| `_grid_sampler_2d_cpu_fallback_backward` | — | — |
| `_grouped_mm` | — | — |
| `_has_compatible_shallow_copy_type` | — | — |
| `_has_same_storage_numel` | — | — |
| `_histogramdd_bin_edges` | — | — |
| `_histogramdd_from_bin_cts` | — | — |
| `_histogramdd_from_bin_tensors` | — | — |
| `_index_put_impl` | — | — |
| `_index_put_impl_` | — | — |
| `_indices` | — | — |
| `_indices_copy` | — | — |
| `_infer_size` | — | — |
| `_int_mm` | — | — |
| `_is_all_true` | — | — |
| `_is_any_true` | — | — |
| `_is_zerotensor` | — | — |
| `_jagged_to_padded_dense_forward` | — | — |
| `_lazy_clone` | — | — |
| `_linalg_check_errors` | — | — |
| `_linalg_det` | — | — |
| `_linalg_eigh` | — | — |
| `_linalg_eigvals` | — | — |
| `_linalg_slogdet` | — | — |
| `_linalg_solve_ex` | — | — |
| `_linalg_svd` | — | — |
| `_list_to_tensor` | — | — |
| `_local_scalar_dense` | ✅ | — |
| `_log_softmax` | ✅ | — |
| `_log_softmax_backward_data` | — | — |
| `_logcumsumexp` | — | — |
| `_lstm_mps` | — | — |
| `_lu_with_info` | — | — |
| `_make_dep_token` | — | — |
| `_make_dual` | — | — |
| `_make_dual_copy` | — | — |
| `_make_per_channel_quantized_tensor` | — | — |
| `_make_per_tensor_quantized_tensor` | — | — |
| `_masked_scale` | — | — |
| `_masked_softmax` | — | — |
| `_masked_softmax_backward` | — | — |
| `_mixed_dtypes_linear` | — | — |
| `_mkldnn_reshape` | — | — |
| `_mkldnn_transpose` | — | — |
| `_mkldnn_transpose_` | — | — |
| `_mps_convolution` | — | — |
| `_mps_convolution_transpose` | — | — |
| `_native_batch_norm_legit` | ✅ | 10 |
| `_native_batch_norm_legit_functional` | — | — |
| `_native_batch_norm_legit_no_training` | ✅ | — |
| `_native_multi_head_attention` | — | — |
| `_ncf_unsqueeze` | — | — |
| `_ncf_view` | — | — |
| `_neg_view` | — | — |
| `_neg_view_copy` | — | — |
| `_nested_compute_contiguous_strides_offsets` | — | — |
| `_nested_from_padded` | — | — |
| `_nested_from_padded_and_nested_example` | — | — |
| `_nested_from_padded_tensor` | — | — |
| `_nested_get_jagged_dummy` | — | — |
| `_nested_get_lengths` | — | — |
| `_nested_get_max_seqlen` | — | — |
| `_nested_get_min_seqlen` | — | — |
| `_nested_get_offsets` | — | — |
| `_nested_get_ragged_idx` | — | — |
| `_nested_get_values` | — | — |
| `_nested_get_values_copy` | — | — |
| `_nested_select_backward` | — | — |
| `_nested_sum_backward` | — | — |
| `_nested_tensor_from_mask` | — | — |
| `_nested_tensor_from_mask_left_aligned` | — | — |
| `_nested_tensor_from_tensor_list` | — | — |
| `_nested_tensor_size` | — | — |
| `_nested_tensor_softmax_with_shape` | — | — |
| `_nested_tensor_storage_offsets` | — | — |
| `_nested_tensor_strides` | — | — |
| `_nested_view_from_buffer` | — | — |
| `_nested_view_from_buffer_copy` | — | — |
| `_nested_view_from_jagged` | — | — |
| `_nested_view_from_jagged_copy` | — | — |
| `_new_zeros_with_same_feature_meta` | — | — |
| `_nnpack_available` | — | — |
| `_nnpack_spatial_convolution` | — | — |
| `_nnz` | — | — |
| `_no_grad_embedding_renorm_` | — | — |
| `_no_grad_fill_` | — | — |
| `_no_grad_normal_` | — | — |
| `_no_grad_uniform_` | — | — |
| `_no_grad_zero_` | — | — |
| `_pack_padded_sequence` | — | — |
| `_pack_padded_sequence_backward` | — | — |
| `_pack_sequence` | — | — |
| `_pad_circular` | — | — |
| `_pad_enum` | — | — |
| `_pad_packed_sequence` | — | — |
| `_padded_dense_to_jagged_forward` | — | — |
| `_pdist_backward` | — | — |
| `_pdist_forward` | ✅ | — |
| `_pin_memory` | — | — |
| `_prelu_kernel` | — | — |
| `_prelu_kernel_backward` | — | — |
| `_print` | — | — |
| `_propagate_xla_data` | — | — |
| `_remove_batch_dim` | — | — |
| `_reshape_alias` | — | — |
| `_reshape_alias_copy` | — | — |
| `_reshape_copy` | — | — |
| `_reshape_from_tensor` | — | — |
| `_resize_output` | — | — |
| `_resize_output_` | — | — |
| `_rowwise_prune` | — | — |
| `_safe_softmax` | — | — |
| `_sample_dirichlet` | — | — |
| `_saturate_weight_to_fp16` | — | — |
| `_scaled_dot_product_attention_math` | — | — |
| `_scaled_dot_product_attention_math_for_mps` | — | — |
| `_scaled_dot_product_cudnn_attention` | — | — |
| `_scaled_dot_product_cudnn_attention_backward` | — | — |
| `_scaled_dot_product_efficient_attention` | — | — |
| `_scaled_dot_product_efficient_attention_backward` | — | — |
| `_scaled_dot_product_flash_attention` | — | — |
| `_scaled_dot_product_flash_attention_backward` | — | — |
| `_scaled_dot_product_flash_attention_for_cpu` | — | — |
| `_scaled_dot_product_flash_attention_for_cpu_backward` | — | — |
| `_scaled_dot_product_fused_attention_overrideable` | — | — |
| `_scaled_dot_product_fused_attention_overrideable_backward` | — | — |
| `_scaled_grouped_mm` | — | — |
| `_scaled_mm` | — | — |
| `_segment_reduce_backward` | — | — |
| `_set_item` | — | — |
| `_shape_as_tensor` | — | — |
| `_size_if_not_equal` | — | — |
| `_slow_conv2d_backward` | — | — |
| `_slow_conv2d_forward` | — | — |
| `_sobol_engine_draw` | — | — |
| `_sobol_engine_ff_` | — | — |
| `_sobol_engine_initialize_state_` | — | — |
| `_sobol_engine_scramble_` | — | — |
| `_softmax` | ✅ | — |
| `_softmax_backward_data` | — | 3 |
| `_sparse_addmm` | — | — |
| `_sparse_broadcast_to` | — | — |
| `_sparse_broadcast_to_copy` | — | — |
| `_sparse_bsc_tensor_unsafe` | — | — |
| `_sparse_bsr_tensor_unsafe` | — | — |
| `_sparse_compressed_tensor_unsafe` | — | — |
| `_sparse_compressed_tensor_with_dims` | — | — |
| `_sparse_coo_tensor_unsafe` | — | — |
| `_sparse_coo_tensor_with_dims` | — | — |
| `_sparse_coo_tensor_with_dims_and_tensors` | — | — |
| `_sparse_csc_tensor_unsafe` | — | — |
| `_sparse_csr_prod` | — | — |
| `_sparse_csr_sum` | — | — |
| `_sparse_csr_tensor_unsafe` | — | — |
| `_sparse_log_softmax` | — | — |
| `_sparse_log_softmax_backward_data` | — | — |
| `_sparse_mask_projection` | — | — |
| `_sparse_mm` | — | — |
| `_sparse_mm_reduce_impl` | — | — |
| `_sparse_mm_reduce_impl_backward` | — | — |
| `_sparse_semi_structured_addmm` | — | — |
| `_sparse_semi_structured_apply` | — | — |
| `_sparse_semi_structured_apply_dense` | — | — |
| `_sparse_semi_structured_linear` | — | — |
| `_sparse_semi_structured_mm` | — | — |
| `_sparse_semi_structured_tile` | — | — |
| `_sparse_softmax` | — | — |
| `_sparse_softmax_backward_data` | — | — |
| `_sparse_sparse_matmul` | — | — |
| `_sparse_sum` | — | — |
| `_sparse_sum_backward` | — | — |
| `_spdiags` | — | — |
| `_spsolve` | — | — |
| `_stack` | — | — |
| `_standard_gamma` | — | — |
| `_standard_gamma_grad` | — | — |
| `_tensor_to_list` | — | — |
| `_test_ambiguous_defaults` | — | — |
| `_test_autograd_multiple_dispatch` | — | — |
| `_test_autograd_multiple_dispatch_view` | — | — |
| `_test_autograd_multiple_dispatch_view_copy` | — | — |
| `_test_check_tensor` | — | — |
| `_test_functorch_fallback` | — | — |
| `_test_optional_filled_intlist` | — | — |
| `_test_optional_floatlist` | — | — |
| `_test_optional_intlist` | — | — |
| `_test_parallel_materialize` | — | — |
| `_test_serialization_subcmul` | — | — |
| `_test_string_default` | — | — |
| `_test_warn_in_autograd` | — | — |
| `_thnn_differentiable_gru_cell_backward` | — | — |
| `_thnn_differentiable_lstm_cell_backward` | — | — |
| `_thnn_fused_gru_cell` | — | — |
| `_thnn_fused_gru_cell_backward` | — | — |
| `_thnn_fused_lstm_cell` | — | — |
| `_thnn_fused_lstm_cell_backward` | — | — |
| `_thnn_fused_lstm_cell_backward_impl` | — | — |
| `_to_copy` | ✅ | — |
| `_to_cpu` | — | — |
| `_to_dense` | — | — |
| `_to_sparse` | — | — |
| `_to_sparse_bsc` | — | — |
| `_to_sparse_bsr` | — | — |
| `_to_sparse_csc` | — | — |
| `_to_sparse_csr` | — | — |
| `_to_sparse_semi_structured` | — | — |
| `_transform_bias_rescale_qkv` | — | — |
| `_transformer_encoder_layer_fwd` | — | — |
| `_trilinear` | — | — |
| `_triton_multi_head_attention` | — | — |
| `_triton_scaled_dot_attention` | — | — |
| `_unique` | — | — |
| `_unique2` | — | — |
| `_unpack_dual` | — | — |
| `_unsafe_index` | — | — |
| `_unsafe_index_put` | — | — |
| `_unsafe_masked_index` | — | 6 |
| `_unsafe_masked_index_put_accumulate` | — | 6 |
| `_unsafe_view` | — | — |
| `_unwrap_optional` | — | — |
| `_upsample_bicubic2d_aa` | — | — |
| `_upsample_bicubic2d_aa_backward` | — | — |
| `_upsample_bilinear2d_aa` | — | 7 |
| `_upsample_bilinear2d_aa_backward` | — | — |
| `_upsample_nearest_exact1d` | — | — |
| `_upsample_nearest_exact1d_backward` | — | — |
| `_upsample_nearest_exact2d` | — | — |
| `_upsample_nearest_exact2d_backward` | — | — |
| `_upsample_nearest_exact3d` | — | — |
| `_upsample_nearest_exact3d_backward` | — | — |
| `_use_cudnn_ctc_loss` | — | — |
| `_use_cudnn_rnn_flatten_weight` | — | — |
| `_validate_compressed_sparse_indices` | — | — |
| `_validate_sparse_bsc_tensor_args` | — | — |
| `_validate_sparse_bsr_tensor_args` | — | — |
| `_validate_sparse_compressed_tensor_args` | — | — |
| `_validate_sparse_coo_tensor_args` | — | — |
| `_validate_sparse_csc_tensor_args` | — | — |
| `_validate_sparse_csr_tensor_args` | — | — |
| `_values` | — | — |
| `_values_copy` | — | — |
| `_version` | — | — |
| `_weight_int4pack_mm` | — | — |
| `_weight_int4pack_mm_for_cpu` | — | — |
| `_weight_int4pack_mm_with_scales_and_zeros` | — | — |
| `_weight_int8pack_mm` | — | — |
| `_weight_norm` | — | — |
| `_weight_norm_differentiable_backward` | — | — |
| `_weight_norm_interface` | — | — |
| `_weight_norm_interface_backward` | — | — |
| `_wrapped_linear_prepack` | — | — |
| `_wrapped_quantized_linear_prepacked` | — | — |
| `abs` | ✅ | 1 |
| `abs_` | ✅ | — |
| `absolute` | ✅ | — |
| `absolute_` | ✅ | — |
| `acos` | ✅ | 3 |
| `acos_` | ✅ | — |
| `acosh` | ✅ | 3 |
| `acosh_` | ✅ | — |
| `adaptive_avg_pool1d` | ✅ | — |
| `adaptive_avg_pool2d` | — | — |
| `adaptive_avg_pool3d` | — | — |
| `adaptive_avg_pool3d_backward` | — | — |
| `adaptive_max_pool1d` | — | — |
| `adaptive_max_pool2d` | — | — |
| `adaptive_max_pool2d_backward` | — | — |
| `adaptive_max_pool3d` | — | — |
| `adaptive_max_pool3d_backward` | — | — |
| `add` | ✅ | 11 |
| `add_` | ✅ | — |
| `addbmm` | ✅ | 6 |
| `addbmm_` | — | — |
| `addcdiv` | — | 12 |
| `addcdiv_` | — | — |
| `addcmul` | — | 12 |
| `addcmul_` | — | — |
| `addmm` | ✅ | 6 |
| `addmm_` | — | — |
| `addmv` | ✅ | 6 |
| `addmv_` | — | — |
| `addr` | ✅ | 6 |
| `addr_` | — | — |
| `adjoint` | — | — |
| `affine_grid_generator` | — | — |
| `affine_grid_generator_backward` | — | — |
| `alias` | ✅ | — |
| `alias_copy` | — | 2 |
| `align_as` | — | — |
| `align_tensors` | — | — |
| `align_to` | — | — |
| `all` | ✅ | 20 |
| `allclose` | — | 24 |
| `alpha_dropout` | — | — |
| `alpha_dropout_` | — | — |
| `amax` | ✅ | 20 |
| `amin` | ✅ | 20 |
| `aminmax` | — | 7 |
| `angle` | ✅ | 1 |
| `any` | ✅ | 20 |
| `append` | — | — |
| `arange` | ✅ | 27 |
| `arccos` | ✅ | — |
| `arccos_` | ✅ | — |
| `arccosh` | — | — |
| `arccosh_` | ✅ | — |
| `arcsin` | ✅ | — |
| `arcsin_` | ✅ | — |
| `arcsinh` | ✅ | — |
| `arcsinh_` | ✅ | — |
| `arctan` | ✅ | — |
| `arctan2` | — | — |
| `arctan2_` | — | — |
| `arctan_` | ✅ | — |
| `arctanh` | — | — |
| `arctanh_` | — | — |
| `argmax` | ✅ | 13 |
| `argmin` | ✅ | 13 |
| `argsort` | — | 58 |
| `argwhere` | — | 6 |
| `as_strided` | ✅ | 5 |
| `as_strided_` | — | — |
| `as_strided_copy` | — | 5 |
| `as_strided_scatter` | — | 7 |
| `as_tensor` | — | — |
| `asin` | ✅ | 1 |
| `asin_` | ✅ | — |
| `asinh` | ✅ | 1 |
| `asinh_` | ✅ | — |
| `atan` | ✅ | 1 |
| `atan2` | ✅ | 9 |
| `atan2_` | ✅ | — |
| `atan_` | ✅ | — |
| `atanh` | ✅ | 1 |
| `atanh_` | ✅ | — |
| `atleast_1d` | — | 6 |
| `atleast_2d` | — | 6 |
| `atleast_3d` | — | 6 |
| `avg_pool1d` | ✅ | 9 |
| `avg_pool2d` | ✅ | 7 |
| `avg_pool2d_backward` | ✅ | — |
| `avg_pool3d` | ✅ | 8 |
| `avg_pool3d_backward` | — | — |
| `backward` | — | — |
| `baddbmm` | — | 6 |
| `baddbmm_` | — | — |
| `bartlett_window` | — | — |
| `batch_norm` | — | 12 |
| `batch_norm_backward` | — | — |
| `batch_norm_backward_elemt` | — | — |
| `batch_norm_backward_reduce` | — | — |
| `batch_norm_elemt` | — | — |
| `batch_norm_gather_stats` | — | — |
| `batch_norm_gather_stats_with_counts` | — | — |
| `batch_norm_stats` | — | — |
| `batch_norm_update_stats` | — | — |
| `bernoulli` | — | 4 |
| `bernoulli_` | — | — |
| `bilinear` | — | 16 |
| `bin` | — | — |
| `binary_cross_entropy` | — | — |
| `binary_cross_entropy_backward` | — | — |
| `binary_cross_entropy_with_logits` | — | 26 |
| `bincount` | — | 16 |
| `binomial` | — | — |
| `bitwise_and` | ✅ | 9 |
| `bitwise_and_` | ✅ | — |
| `bitwise_left_shift` | ✅ | 9 |
| `bitwise_left_shift_` | ✅ | — |
| `bitwise_not` | ✅ | 3 |
| `bitwise_not_` | ✅ | — |
| `bitwise_or` | ✅ | 9 |
| `bitwise_or_` | ✅ | — |
| `bitwise_right_shift` | ✅ | 9 |
| `bitwise_right_shift_` | ✅ | — |
| `bitwise_xor` | ✅ | 9 |
| `bitwise_xor_` | ✅ | — |
| `blackman_window` | — | — |
| `block_diag` | — | 4 |
| `bmm` | ✅ | 1 |
| `broadcast_tensors` | — | 1 |
| `broadcast_to` | — | 7 |
| `bucketize` | — | 24 |
| `can_cast` | — | — |
| `capitalize` | — | — |
| `cartesian_prod` | — | 3 |
| `cat` | ✅ | 9 |
| `cauchy` | — | 3 |
| `cauchy_` | — | — |
| `ccol_indices` | — | — |
| `ccol_indices_copy` | — | — |
| `cdist` | — | 256 |
| `ceil` | ✅ | 1 |
| `ceil_` | ✅ | — |
| `celu` | — | — |
| `celu_` | — | — |
| `center` | — | — |
| `chain_matmul` | — | — |
| `chalf` | — | 5 |
| `channel_shuffle` | — | — |
| `cholesky` | — | 16 |
| `cholesky_inverse` | — | 12 |
| `cholesky_solve` | — | 12 |
| `choose_qparams_optimized` | — | — |
| `chr` | — | — |
| `chunk` | — | 3 |
| `clamp` | ✅ | 7 |
| `clamp_` | ✅ | — |
| `clamp_max` | ✅ | 9 |
| `clamp_max_` | ✅ | — |
| `clamp_min` | ✅ | 9 |
| `clamp_min_` | ✅ | — |
| `clear` | — | — |
| `clip` | — | — |
| `clip_` | — | — |
| `clone` | ✅ | 2 |
| `coalesce` | — | — |
| `col2im` | ✅ | — |
| `col_indices` | — | — |
| `col_indices_copy` | — | — |
| `column_stack` | — | 3 |
| `combinations` | — | 18 |
| `complex` | — | 9 |
| `concat` | — | — |
| `concatenate` | — | — |
| `confirmed_by_owner` | — | — |
| `conj` | ✅ | 3 |
| `conj_physical` | ✅ | 1 |
| `conj_physical_` | ✅ | — |
| `constant_pad_nd` | ✅ | 49 |
| `contiguous` | — | 2 |
| `conv1d` | ✅ | 10 |
| `conv2d` | ✅ | 30 |
| `conv3d` | — | 20 |
| `conv_depthwise3d` | — | — |
| `conv_tbc` | — | — |
| `conv_tbc_backward` | — | — |
| `conv_transpose1d` | — | 10 |
| `conv_transpose2d` | — | 12 |
| `conv_transpose3d` | — | 10 |
| `convolution` | ✅ | — |
| `convolution_backward` | — | — |
| `convolution_backward_overrideable` | — | — |
| `convolution_overrideable` | — | — |
| `copy` | ✅ | — |
| `copy_` | — | — |
| `copy_sparse_to_sparse` | — | — |
| `copy_sparse_to_sparse_` | — | — |
| `copysign` | ✅ | 10 |
| `copysign_` | ✅ | — |
| `corrcoef` | — | 4 |
| `cos` | ✅ | 3 |
| `cos_` | ✅ | — |
| `cosh` | ✅ | 3 |
| `cosh_` | ✅ | — |
| `cosine_embedding_loss` | — | — |
| `cosine_similarity` | — | 9 |
| `count` | — | — |
| `count_nonzero` | — | 20 |
| `cov` | — | 40 |
| `cpu` | — | — |
| `cross` | — | 3 |
| `cross_entropy_loss` | — | — |
| `crow_indices` | — | — |
| `crow_indices_copy` | — | — |
| `ctc_loss` | — | — |
| `cuda` | — | — |
| `cudnn_affine_grid_generator` | — | — |
| `cudnn_affine_grid_generator_backward` | — | — |
| `cudnn_batch_norm` | — | — |
| `cudnn_batch_norm_backward` | — | — |
| `cudnn_convolution` | — | — |
| `cudnn_convolution_add_relu` | — | — |
| `cudnn_convolution_relu` | — | — |
| `cudnn_convolution_transpose` | — | — |
| `cudnn_grid_sampler` | — | — |
| `cudnn_grid_sampler_backward` | — | — |
| `cudnn_is_acceptable` | — | — |
| `cummax` | — | 3 |
| `cummaxmin_backward` | — | — |
| `cummin` | — | 3 |
| `cumprod` | — | 10 |
| `cumprod_` | — | — |
| `cumprod_backward` | — | — |
| `cumsum` | ✅ | 4 |
| `cumsum_` | — | — |
| `cumulative_trapezoid` | — | 9 |
| `data` | — | — |
| `deg2rad` | ✅ | 1 |
| `deg2rad_` | ✅ | — |
| `degrees` | — | — |
| `dense_dim` | — | — |
| `dequantize` | — | — |
| `det` | — | — |
| `detach` | — | — |
| `detach_` | — | — |
| `detach_copy` | — | — |
| `device` | — | — |
| `diag` | — | 16 |
| `diag_embed` | — | 15 |
| `diagflat` | — | 5 |
| `diagonal` | ✅ | 15 |
| `diagonal_backward` | — | — |
| `diagonal_copy` | — | 15 |
| `diagonal_scatter` | — | 15 |
| `dict` | — | — |
| `diff` | — | 64 |
| `digamma` | ✅ | 3 |
| `digamma_` | ✅ | — |
| `dim` | — | — |
| `dist` | — | 50 |
| `dist_backward` | — | — |
| `div` | ✅ | — |
| `div_` | ✅ | — |
| `divide` | — | — |
| `divide_` | — | — |
| `divmod` | — | — |
| `dot` | — | 1 |
| `dropout` | — | — |
| `dropout_` | — | — |
| `dsplit` | — | 2 |
| `dstack` | — | 2 |
| `einsum` | — | 11 |
| `element_size` | — | — |
| `elu` | ✅ | — |
| `elu_` | ✅ | — |
| `elu_backward` | — | — |
| `embedding` | ✅ | — |
| `embedding_backward` | — | — |
| `embedding_bag` | — | — |
| `embedding_dense_backward` | ✅ | — |
| `embedding_renorm` | — | — |
| `embedding_renorm_` | — | — |
| `embedding_sparse_backward` | — | — |
| `empty` | — | 6 |
| `empty_like` | — | 7 |
| `empty_permuted` | — | 39 |
| `empty_quantized` | — | — |
| `empty_strided` | ✅ | 4 |
| `endswith` | — | — |
| `eq` | ✅ | 10 |
| `eq_` | — | — |
| `equal` | — | 8 |
| `erf` | ✅ | 1 |
| `erf_` | ✅ | — |
| `erfc` | ✅ | 3 |
| `erfc_` | ✅ | — |
| `erfinv` | ✅ | 1 |
| `erfinv_` | ✅ | — |
| `exp` | ✅ | 3 |
| `exp2` | ✅ | 3 |
| `exp2_` | ✅ | — |
| `exp_` | ✅ | — |
| `expand` | ✅ | 9 |
| `expand_as` | — | 3 |
| `expand_copy` | — | 9 |
| `expandtabs` | — | — |
| `expm1` | ✅ | 1 |
| `expm1_` | ✅ | — |
| `exponential` | — | 3 |
| `exponential_` | — | — |
| `extend` | — | — |
| `eye` | — | 90 |
| `fabs` | — | — |
| `factorial` | — | — |
| `fake_quantize_per_channel_affine` | — | — |
| `fake_quantize_per_channel_affine_cachemask` | — | — |
| `fake_quantize_per_channel_affine_cachemask_backward` | — | — |
| `fake_quantize_per_tensor_affine` | — | — |
| `fake_quantize_per_tensor_affine_cachemask` | — | — |
| `fake_quantize_per_tensor_affine_cachemask_backward` | — | — |
| `fbgemm_linear_fp16_weight` | — | — |
| `fbgemm_linear_fp16_weight_fp32_activation` | — | — |
| `fbgemm_linear_int8_weight` | — | — |
| `fbgemm_linear_int8_weight_fp32_activation` | — | — |
| `fbgemm_linear_quantize_weight` | — | — |
| `fbgemm_pack_gemm_matrix_fp16` | — | — |
| `fbgemm_pack_quantized_matrix` | — | — |
| `feature_alpha_dropout` | — | — |
| `feature_alpha_dropout_` | — | — |
| `feature_dropout` | — | — |
| `feature_dropout_` | — | — |
| `fft_fft` | — | 8 |
| `fft_fft2` | — | 7 |
| `fft_fftfreq` | — | — |
| `fft_fftn` | — | 9 |
| `fft_fftshift` | — | — |
| `fft_hfft` | — | 8 |
| `fft_hfft2` | — | 7 |
| `fft_hfftn` | — | 9 |
| `fft_ifft` | — | 8 |
| `fft_ifft2` | — | 7 |
| `fft_ifftn` | — | 9 |
| `fft_ifftshift` | — | — |
| `fft_ihfft` | — | 8 |
| `fft_ihfft2` | — | 7 |
| `fft_ihfftn` | — | 9 |
| `fft_irfft` | — | 8 |
| `fft_irfft2` | — | 7 |
| `fft_irfftn` | — | 9 |
| `fft_rfft` | — | 8 |
| `fft_rfft2` | — | 7 |
| `fft_rfftfreq` | — | — |
| `fft_rfftn` | — | 9 |
| `fill` | ✅ | 3 |
| `fill_` | ✅ | — |
| `fill_diagonal_` | — | — |
| `find` | — | — |
| `fix` | — | — |
| `fix_` | — | — |
| `flatten` | ✅ | 6 |
| `flatten_dense_tensors` | — | — |
| `flip` | ✅ | 10 |
| `fliplr` | — | 2 |
| `flipud` | — | 2 |
| `float_power` | — | 9 |
| `float_power_` | — | — |
| `floor` | ✅ | 1 |
| `floor_` | ✅ | — |
| `floor_divide` | ✅ | 9 |
| `floor_divide_` | ✅ | — |
| `floordiv` | — | — |
| `fmax` | ✅ | 9 |
| `fmin` | ✅ | 9 |
| `fmod` | ✅ | 9 |
| `fmod_` | ✅ | — |
| `format` | — | — |
| `frac` | ✅ | 1 |
| `frac_` | ✅ | — |
| `fractional_max_pool2d` | — | — |
| `fractional_max_pool2d_backward` | — | — |
| `fractional_max_pool3d` | — | — |
| `fractional_max_pool3d_backward` | — | — |
| `frexp` | — | 3 |
| `frobenius_norm` | — | — |
| `from_file` | — | — |
| `full` | — | 4 |
| `full_like` | ✅ | 7 |
| `fused_moving_avg_obs_fake_quant` | — | — |
| `gamma` | — | — |
| `gather` | ✅ | 7 |
| `gather_backward` | — | — |
| `gcd` | — | 9 |
| `gcd_` | — | — |
| `ge` | ✅ | 9 |
| `ge_` | — | — |
| `gelu` | ✅ | 8 |
| `gelu_` | ✅ | — |
| `gelu_backward` | — | — |
| `geometric` | — | 3 |
| `geometric_` | — | — |
| `geqrf` | — | 36 |
| `ger` | — | — |
| `get` | — | — |
| `get_autocast_dtype` | — | — |
| `get_device` | — | — |
| `get_gradients` | — | — |
| `glu` | — | 46 |
| `glu_backward` | — | — |
| `glu_backward_jvp` | — | — |
| `glu_jvp` | — | — |
| `grad` | — | — |
| `gradient` | — | 8 |
| `greater` | — | — |
| `greater_` | — | — |
| `greater_equal` | — | — |
| `greater_equal_` | — | — |
| `grid_sampler` | — | — |
| `grid_sampler_2d` | — | 18 |
| `grid_sampler_2d_backward` | — | — |
| `grid_sampler_3d` | — | 30 |
| `grid_sampler_3d_backward` | — | — |
| `group_norm` | — | 21 |
| `gru` | — | — |
| `gru_cell` | — | — |
| `gt` | ✅ | 9 |
| `gt_` | — | — |
| `hamming_window` | — | — |
| `hann_window` | — | — |
| `hardshrink` | — | 6 |
| `hardshrink_backward` | — | — |
| `hardsigmoid` | ✅ | — |
| `hardsigmoid_` | — | — |
| `hardsigmoid_backward` | — | — |
| `hardswish` | ✅ | 4 |
| `hardswish_` | ✅ | — |
| `hardswish_backward` | — | — |
| `hardtanh` | ✅ | 5 |
| `hardtanh_` | ✅ | — |
| `hardtanh_backward` | — | — |
| `has_torch_function` | — | — |
| `hash` | — | — |
| `hash_tensor` | — | 20 |
| `heaviside` | ✅ | 9 |
| `heaviside_` | ✅ | — |
| `hex` | — | — |
| `hinge_embedding_loss` | — | — |
| `histc` | — | 96 |
| `histogram` | — | 192 |
| `histogramdd` | — | 96 |
| `hsplit` | — | 2 |
| `hspmm` | — | — |
| `hstack` | — | 2 |
| `huber_loss` | — | — |
| `huber_loss_backward` | — | — |
| `hypot` | ✅ | 9 |
| `hypot_` | ✅ | — |
| `i0` | ✅ | 2 |
| `i0_` | ✅ | — |
| `igamma` | — | 9 |
| `igamma_` | — | — |
| `igammac` | — | 9 |
| `igammac_` | — | — |
| `im2col` | — | 163 |
| `imag` | — | 3 |
| `index` | — | — |
| `index_add` | — | 9 |
| `index_add_` | — | — |
| `index_copy` | — | 3 |
| `index_copy_` | — | — |
| `index_fill` | — | 6 |
| `index_fill_` | — | — |
| `index_put` | ✅ | 4 |
| `index_put_` | ✅ | — |
| `index_reduce` | — | — |
| `index_reduce_` | — | — |
| `index_select` | ✅ | 3 |
| `index_select_backward` | — | — |
| `indices` | — | — |
| `indices_copy` | — | — |
| `infinitely_differentiable_gelu_backward` | — | — |
| `initial_seed` | — | — |
| `inner` | — | 2 |
| `insert` | — | — |
| `instance_norm` | — | — |
| `int_repr` | — | — |
| `inverse` | — | — |
| `is_autocast_cpu_enabled` | — | — |
| `is_autocast_enabled` | — | — |
| `is_coalesced` | — | — |
| `is_complex` | — | — |
| `is_conj` | — | — |
| `is_contiguous` | — | — |
| `is_distributed` | — | — |
| `is_floating_point` | — | — |
| `is_grad_enabled` | — | — |
| `is_inference` | — | — |
| `is_leaf` | — | — |
| `is_neg` | — | — |
| `is_non_overlapping_and_dense` | — | — |
| `is_nonzero` | — | — |
| `is_owner` | — | — |
| `is_pinned` | — | — |
| `is_same_size` | — | — |
| `is_scripting` | — | — |
| `is_set_to` | — | — |
| `is_signed` | — | — |
| `is_strides_like_format` | — | — |
| `is_vulkan_available` | — | — |
| `isalnum` | — | — |
| `isalpha` | — | — |
| `isclose` | — | 17 |
| `isdecimal` | — | — |
| `isdigit` | — | — |
| `isfinite` | ✅ | 3 |
| `isidentifier` | — | — |
| `isin` | — | 2 |
| `isinf` | ✅ | 1 |
| `islower` | — | — |
| `isnan` | ✅ | 1 |
| `isneginf` | ✅ | 1 |
| `isnumeric` | — | — |
| `isposinf` | ✅ | 1 |
| `isprintable` | — | — |
| `isreal` | — | 3 |
| `isspace` | — | — |
| `istft` | — | 10 |
| `istitle` | — | — |
| `isupper` | — | — |
| `item` | — | 4 |
| `items` | — | — |
| `join` | — | — |
| `kaiser_window` | — | — |
| `keys` | — | — |
| `kl_div` | — | — |
| `kron` | — | 1 |
| `kthvalue` | — | 10 |
| `l1_loss` | — | — |
| `layer_norm` | — | 6 |
| `lcm` | — | 9 |
| `lcm_` | — | — |
| `ldexp` | ✅ | 9 |
| `ldexp_` | ✅ | — |
| `le` | ✅ | 9 |
| `le_` | — | — |
| `leaky_relu` | ✅ | 9 |
| `leaky_relu_` | ✅ | — |
| `leaky_relu_backward` | — | — |
| `len` | — | — |
| `lerp` | — | 14 |
| `lerp_` | — | — |
| `less` | — | — |
| `less_` | — | — |
| `less_equal` | — | — |
| `less_equal_` | — | — |
| `lgamma` | ✅ | 3 |
| `lgamma_` | ✅ | — |
| `lift` | — | — |
| `lift_fresh` | — | — |
| `lift_fresh_copy` | — | — |
| `linalg_cholesky` | — | 16 |
| `linalg_cholesky_ex` | — | 16 |
| `linalg_cond` | — | 3 |
| `linalg_cross` | — | 3 |
| `linalg_det` | — | 9 |
| `linalg_diagonal` | — | 15 |
| `linalg_eig` | — | 8 |
| `linalg_eigh` | — | 8 |
| `linalg_eigvals` | — | 8 |
| `linalg_eigvalsh` | — | 8 |
| `linalg_householder_product` | — | 8 |
| `linalg_inv` | — | 8 |
| `linalg_inv_ex` | — | 8 |
| `linalg_ldl_factor` | — | 6 |
| `linalg_ldl_factor_ex` | — | 6 |
| `linalg_ldl_solve` | — | 24 |
| `linalg_lstsq` | — | 36 |
| `linalg_lu` | — | 15 |
| `linalg_lu_factor` | — | 15 |
| `linalg_lu_factor_ex` | — | 15 |
| `linalg_lu_solve` | — | 108 |
| `linalg_matmul` | — | — |
| `linalg_matrix_exp` | — | — |
| `linalg_matrix_norm` | — | 40 |
| `linalg_matrix_power` | — | 18 |
| `linalg_matrix_rank` | — | 72 |
| `linalg_multi_dot` | — | 7 |
| `linalg_norm` | — | 78 |
| `linalg_pinv` | — | 24 |
| `linalg_qr` | — | 36 |
| `linalg_slogdet` | — | 9 |
| `linalg_solve` | — | 24 |
| `linalg_solve_ex` | — | 24 |
| `linalg_solve_triangular` | — | 144 |
| `linalg_svd` | — | 216 |
| `linalg_svdvals` | — | 36 |
| `linalg_tensorinv` | — | — |
| `linalg_tensorsolve` | — | — |
| `linalg_vander` | — | 10 |
| `linalg_vecdot` | — | 44 |
| `linalg_vector_norm` | — | 180 |
| `linear` | ✅ | 18 |
| `linear_backward` | — | — |
| `linspace` | — | 62 |
| `list` | — | — |
| `ljust` | — | — |
| `local_value` | — | — |
| `log` | ✅ | 3 |
| `log10` | ✅ | 3 |
| `log10_` | ✅ | — |
| `log1p` | ✅ | 1 |
| `log1p_` | ✅ | — |
| `log2` | ✅ | 3 |
| `log2_` | ✅ | — |
| `log_` | ✅ | — |
| `log_normal` | — | 3 |
| `log_normal_` | — | — |
| `log_sigmoid` | ✅ | 3 |
| `log_sigmoid_backward` | — | — |
| `log_sigmoid_forward` | — | — |
| `log_softmax` | ✅ | 7 |
| `logaddexp` | ✅ | 9 |
| `logaddexp2` | ✅ | 1 |
| `logcumsumexp` | — | 6 |
| `logdet` | — | 9 |
| `logical_and` | ✅ | 9 |
| `logical_and_` | ✅ | — |
| `logical_not` | ✅ | 3 |
| `logical_not_` | ✅ | — |
| `logical_or` | ✅ | 9 |
| `logical_or_` | ✅ | — |
| `logical_xor` | ✅ | 9 |
| `logical_xor_` | ✅ | — |
| `logit` | ✅ | 4 |
| `logit_` | ✅ | — |
| `logit_backward` | — | — |
| `logspace` | — | 401 |
| `logsumexp` | — | 5 |
| `lower` | — | — |
| `lstm` | — | — |
| `lstm_cell` | — | — |
| `lstm_mps_backward` | — | — |
| `lstrip` | — | — |
| `lt` | ✅ | 9 |
| `lt_` | — | — |
| `lu_solve` | — | 27 |
| `lu_unpack` | — | 15 |
| `mH` | — | 5 |
| `mT` | — | 5 |
| `manual_seed` | — | — |
| `margin_ranking_loss` | — | — |
| `masked_fill` | — | 8 |
| `masked_fill_` | — | — |
| `masked_scatter` | ✅ | 4 |
| `masked_scatter_` | ✅ | — |
| `masked_scatter_backward` | — | — |
| `masked_select` | — | 7 |
| `masked_select_backward` | — | — |
| `mathremainder` | — | — |
| `matmul` | ✅ | 15 |
| `matmul_backward` | — | — |
| `matrix_H` | — | — |
| `matrix_exp` | — | 2 |
| `matrix_exp_backward` | — | — |
| `matrix_power` | — | — |
| `max` | ✅ | — |
| `max_pool1d` | ✅ | 864 |
| `max_pool1d_with_indices` | — | — |
| `max_pool2d` | ✅ | 1440 |
| `max_pool2d_backward` | — | — |
| `max_pool2d_with_indices` | — | — |
| `max_pool2d_with_indices_backward` | — | 1440 |
| `max_pool3d` | — | 576 |
| `max_pool3d_with_indices` | — | — |
| `max_pool3d_with_indices_backward` | — | — |
| `max_unpool2d` | — | 288 |
| `max_unpool3d` | — | 96 |
| `maximum` | ✅ | 9 |
| `mean` | ✅ | 20 |
| `median` | — | 13 |
| `meshgrid` | — | — |
| `min` | ✅ | — |
| `minimum` | ✅ | 9 |
| `miopen_batch_norm` | — | — |
| `miopen_batch_norm_backward` | — | — |
| `miopen_convolution` | — | — |
| `miopen_convolution_add_relu` | — | — |
| `miopen_convolution_relu` | — | — |
| `miopen_convolution_transpose` | — | — |
| `miopen_depthwise_convolution` | — | — |
| `miopen_rnn` | — | — |
| `miopen_rnn_backward` | — | — |
| `mish` | — | — |
| `mish_` | ✅ | — |
| `mish_backward` | — | — |
| `mkldnn_adaptive_avg_pool2d` | — | — |
| `mkldnn_adaptive_avg_pool2d_backward` | — | — |
| `mkldnn_convolution` | — | — |
| `mkldnn_linear` | — | — |
| `mkldnn_linear_backward` | — | — |
| `mkldnn_linear_backward_input` | — | — |
| `mkldnn_linear_backward_weights` | — | — |
| `mkldnn_max_pool2d` | — | — |
| `mkldnn_max_pool2d_backward` | — | — |
| `mkldnn_max_pool3d` | — | — |
| `mkldnn_max_pool3d_backward` | — | — |
| `mkldnn_reorder_conv2d_weight` | — | — |
| `mkldnn_reorder_conv3d_weight` | — | — |
| `mkldnn_rnn_layer` | — | — |
| `mkldnn_rnn_layer_backward` | — | — |
| `mm` | ✅ | 3 |
| `mode` | — | 7 |
| `modf` | — | — |
| `moveaxis` | — | — |
| `movedim` | — | 2 |
| `mps_convolution_backward` | — | — |
| `mps_convolution_transpose_backward` | — | — |
| `mse_loss` | — | — |
| `mse_loss_backward` | — | — |
| `msort` | — | 2 |
| `mul` | ✅ | 9 |
| `mul_` | ✅ | — |
| `multi_margin_loss` | — | — |
| `multi_margin_loss_backward` | — | — |
| `multilabel_margin_loss` | — | — |
| `multilabel_margin_loss_backward` | — | — |
| `multilabel_margin_loss_forward` | — | — |
| `multinomial` | — | 7 |
| `multiply` | — | — |
| `multiply_` | — | — |
| `mv` | — | 1 |
| `mvlgamma` | — | — |
| `mvlgamma_` | — | — |
| `nan_to_num` | ✅ | 3 |
| `nan_to_num_` | ✅ | — |
| `nanmean` | — | 35 |
| `nanmedian` | — | 13 |
| `nanquantile` | — | 60 |
| `nansum` | — | 35 |
| `narrow` | ✅ | 10 |
| `narrow_copy` | — | 5 |
| `native_batch_norm` | — | 10 |
| `native_batch_norm_backward` | — | — |
| `native_channel_shuffle` | — | — |
| `native_dropout` | ✅ | — |
| `native_dropout_backward` | — | 9 |
| `native_group_norm` | — | — |
| `native_group_norm_backward` | — | — |
| `native_layer_norm` | — | 20 |
| `native_layer_norm_backward` | — | — |
| `native_norm` | — | — |
| `ne` | ✅ | 9 |
| `ne_` | — | — |
| `neg` | ✅ | 1 |
| `neg_` | ✅ | — |
| `negative` | — | — |
| `negative_` | — | — |
| `nested_to_padded_tensor` | — | — |
| `new_empty` | — | 7 |
| `new_empty_strided` | — | 7 |
| `new_full` | — | 7 |
| `new_ones` | — | 7 |
| `new_zeros` | — | 7 |
| `nextafter` | ✅ | 9 |
| `nextafter_` | ✅ | — |
| `nll_loss` | — | — |
| `nll_loss2d` | — | — |
| `nll_loss2d_backward` | — | — |
| `nll_loss2d_forward` | — | — |
| `nll_loss_backward` | — | — |
| `nll_loss_forward` | — | — |
| `nll_loss_nd` | — | — |
| `nonzero` | ✅ | 24 |
| `nonzero_numpy` | — | — |
| `nonzero_static` | — | 60 |
| `norm` | ✅ | 42 |
| `norm_except_dim` | — | — |
| `normal` | — | 5 |
| `normal_` | — | — |
| `normal_functional` | — | — |
| `not_equal` | — | — |
| `not_equal_` | — | — |
| `nuclear_norm` | — | — |
| `numel` | — | — |
| `numpy_T` | — | — |
| `oct` | — | — |
| `one_hot` | — | — |
| `ones` | — | 2 |
| `ones_like` | — | 7 |
| `ord` | — | — |
| `orgqr` | — | — |
| `ormqr` | — | 144 |
| `outer` | — | 1 |
| `output_nr` | — | — |
| `owner` | — | — |
| `owner_name` | — | — |
| `pad` | — | — |
| `pad_sequence` | — | — |
| `pairwise_distance` | — | — |
| `partition` | — | — |
| `pdist` | — | — |
| `percentFormat` | — | — |
| `permute` | ✅ | 4 |
| `permute_copy` | — | 4 |
| `pin_memory` | — | — |
| `pinverse` | — | 8 |
| `pixel_shuffle` | — | — |
| `pixel_unshuffle` | — | — |
| `poisson` | — | — |
| `poisson_nll_loss` | — | — |
| `polar` | — | 9 |
| `polygamma` | — | — |
| `polygamma_` | — | — |
| `pop` | — | — |
| `popitem` | — | — |
| `positive` | ✅ | 1 |
| `pow` | ✅ | 9 |
| `pow_` | ✅ | — |
| `prelu` | — | — |
| `prod` | ✅ | 39 |
| `promote_types` | — | — |
| `put` | — | 28 |
| `put_` | — | — |
| `q_per_channel_axis` | — | — |
| `q_per_channel_scales` | — | — |
| `q_per_channel_zero_points` | — | — |
| `q_scale` | — | — |
| `q_zero_point` | — | — |
| `qr` | — | 36 |
| `qscheme` | — | — |
| `quantile` | — | 60 |
| `quantize_per_channel` | — | — |
| `quantize_per_tensor` | — | — |
| `quantize_per_tensor_dynamic` | — | — |
| `quantized_batch_norm` | — | — |
| `quantized_gru` | — | — |
| `quantized_gru_cell` | — | — |
| `quantized_lstm` | — | — |
| `quantized_lstm_cell` | — | — |
| `quantized_max_pool1d` | — | — |
| `quantized_max_pool2d` | — | — |
| `quantized_max_pool3d` | — | — |
| `quantized_rnn_relu_cell` | — | — |
| `quantized_rnn_tanh_cell` | — | — |
| `rad2deg` | ✅ | 1 |
| `rad2deg_` | ✅ | — |
| `radians` | — | — |
| `rand` | — | — |
| `rand_like` | — | 7 |
| `randint` | — | 14 |
| `randint_like` | — | 14 |
| `randn` | — | 2 |
| `randn_like` | — | 7 |
| `random` | — | — |
| `random_` | — | — |
| `randperm` | — | — |
| `range` | — | — |
| `ravel` | — | 3 |
| `real` | ✅ | 3 |
| `reciprocal` | ✅ | 3 |
| `reciprocal_` | ✅ | — |
| `record_stream` | — | — |
| `refine_names` | — | — |
| `reflection_pad1d` | — | — |
| `reflection_pad1d_backward` | — | — |
| `reflection_pad2d` | — | — |
| `reflection_pad2d_backward` | — | — |
| `reflection_pad3d` | — | — |
| `reflection_pad3d_backward` | — | — |
| `relu` | ✅ | 4 |
| `relu6` | ✅ | 3 |
| `relu6_` | — | — |
| `relu_` | ✅ | — |
| `remainder` | ✅ | 9 |
| `remainder_` | ✅ | — |
| `remove` | — | — |
| `rename` | — | — |
| `rename_` | — | — |
| `renorm` | — | 4 |
| `renorm_` | — | — |
| `repeat` | ✅ | 40 |
| `repeat_interleave` | — | 5 |
| `replace` | — | — |
| `replication_pad1d` | — | — |
| `replication_pad1d_backward` | — | — |
| `replication_pad2d` | — | — |
| `replication_pad2d_backward` | — | — |
| `replication_pad3d` | — | — |
| `replication_pad3d_backward` | — | — |
| `requires_grad_` | — | — |
| `reshape` | ✅ | 7 |
| `reshape_as` | — | 4 |
| `resize` | — | — |
| `resize_` | ✅ | 3 |
| `resize_as` | — | — |
| `resize_as_` | — | 3 |
| `resize_as_sparse` | — | — |
| `resize_as_sparse_` | — | — |
| `resolve_conj` | — | 2 |
| `resolve_neg` | — | 2 |
| `result_type` | — | — |
| `retain_grad` | — | — |
| `retains_grad` | — | — |
| `reverse` | — | — |
| `rfind` | — | — |
| `rindex` | — | — |
| `rjust` | — | — |
| `rms_norm` | — | 6 |
| `rnn_relu` | — | — |
| `rnn_relu_cell` | — | — |
| `rnn_tanh` | — | — |
| `rnn_tanh_cell` | — | — |
| `roll` | — | 17 |
| `rot90` | — | 34 |
| `round` | ✅ | 1 |
| `round_` | ✅ | — |
| `row_indices` | — | — |
| `row_indices_copy` | — | — |
| `row_stack` | — | — |
| `rpartition` | — | — |
| `rrelu` | — | — |
| `rrelu_` | — | — |
| `rrelu_with_noise` | — | — |
| `rrelu_with_noise_` | — | — |
| `rrelu_with_noise_backward` | — | — |
| `rrelu_with_noise_functional` | — | — |
| `rsplit` | — | — |
| `rsqrt` | ✅ | 3 |
| `rsqrt_` | ✅ | — |
| `rstrip` | — | — |
| `rsub` | — | 11 |
| `save` | — | — |
| `scalar_tensor` | ✅ | 3 |
| `scaled_dot_product_attention` | — | — |
| `scatter` | — | 27 |
| `scatter_` | — | — |
| `scatter_add` | — | 7 |
| `scatter_add_` | — | — |
| `scatter_reduce` | — | — |
| `scatter_reduce_` | — | — |
| `searchsorted` | — | 288 |
| `seed` | — | — |
| `segment_reduce` | — | — |
| `select` | ✅ | 6 |
| `select_backward` | — | — |
| `select_copy` | — | — |
| `select_scatter` | ✅ | 5 |
| `selu` | ✅ | — |
| `selu_` | — | — |
| `set` | — | — |
| `set_` | — | — |
| `set_data` | — | — |
| `set_grad_enabled` | — | — |
| `setdefault` | — | — |
| `sgn` | ✅ | 1 |
| `sgn_` | ✅ | — |
| `sigmoid` | ✅ | 3 |
| `sigmoid_` | ✅ | — |
| `sigmoid_backward` | — | — |
| `sign` | ✅ | 1 |
| `sign_` | ✅ | — |
| `signbit` | — | 1 |
| `silu` | — | — |
| `silu_` | ✅ | — |
| `silu_backward` | — | — |
| `sin` | ✅ | 1 |
| `sin_` | ✅ | — |
| `sinc` | ✅ | 3 |
| `sinc_` | ✅ | — |
| `sinh` | ✅ | 1 |
| `sinh_` | ✅ | — |
| `size` | — | — |
| `slice` | ✅ | 4 |
| `slice_backward` | — | — |
| `slice_copy` | — | — |
| `slice_inverse` | — | — |
| `slice_scatter` | — | 9 |
| `slogdet` | — | — |
| `slow_conv3d` | — | — |
| `slow_conv3d_forward` | — | — |
| `slow_conv_dilated2d` | — | — |
| `slow_conv_dilated3d` | — | — |
| `slow_conv_transpose2d` | — | — |
| `slow_conv_transpose3d` | — | — |
| `smm` | — | — |
| `smooth_l1_loss` | — | — |
| `smooth_l1_loss_backward` | — | — |
| `soft_margin_loss` | — | — |
| `soft_margin_loss_backward` | — | — |
| `softmax` | ✅ | 7 |
| `softplus` | ✅ | — |
| `softplus_backward` | — | — |
| `softshrink` | — | 5 |
| `softshrink_backward` | — | — |
| `sort` | — | 58 |
| `sorted` | — | — |
| `sparse_bsc_tensor` | — | — |
| `sparse_bsr_tensor` | — | — |
| `sparse_compressed_tensor` | — | — |
| `sparse_coo_tensor` | — | — |
| `sparse_csc_tensor` | — | — |
| `sparse_csr_tensor` | — | — |
| `sparse_dim` | — | — |
| `sparse_mask` | — | — |
| `sparse_resize` | — | — |
| `sparse_resize_` | — | — |
| `sparse_resize_and_clear` | — | — |
| `sparse_resize_and_clear_` | — | — |
| `sparse_sampled_addmm` | — | — |
| `special_airy_ai` | — | — |
| `special_bessel_j0` | — | — |
| `special_bessel_j1` | — | — |
| `special_bessel_y0` | — | — |
| `special_bessel_y1` | — | — |
| `special_chebyshev_polynomial_t` | — | — |
| `special_chebyshev_polynomial_u` | — | — |
| `special_chebyshev_polynomial_v` | — | — |
| `special_chebyshev_polynomial_w` | — | — |
| `special_digamma` | — | — |
| `special_entr` | — | 2 |
| `special_erf` | — | — |
| `special_erfc` | — | — |
| `special_erfcx` | — | 3 |
| `special_erfinv` | — | — |
| `special_exp2` | — | — |
| `special_expit` | — | — |
| `special_expm1` | — | — |
| `special_gammainc` | — | — |
| `special_gammaincc` | — | — |
| `special_gammaln` | — | — |
| `special_hermite_polynomial_h` | — | — |
| `special_hermite_polynomial_he` | — | — |
| `special_i0` | — | — |
| `special_i0e` | — | 2 |
| `special_i1` | — | 2 |
| `special_i1e` | — | 2 |
| `special_laguerre_polynomial_l` | — | — |
| `special_legendre_polynomial_p` | — | — |
| `special_log1p` | — | — |
| `special_log_ndtr` | — | 3 |
| `special_log_softmax` | — | — |
| `special_logit` | — | — |
| `special_logsumexp` | — | — |
| `special_modified_bessel_i0` | — | — |
| `special_modified_bessel_i1` | — | — |
| `special_modified_bessel_k0` | — | — |
| `special_modified_bessel_k1` | — | — |
| `special_multigammaln` | — | — |
| `special_ndtr` | — | 3 |
| `special_ndtri` | — | 3 |
| `special_polygamma` | — | — |
| `special_psi` | — | — |
| `special_round` | — | — |
| `special_scaled_modified_bessel_k0` | — | — |
| `special_scaled_modified_bessel_k1` | — | — |
| `special_shifted_chebyshev_polynomial_t` | — | — |
| `special_shifted_chebyshev_polynomial_u` | — | — |
| `special_shifted_chebyshev_polynomial_v` | — | — |
| `special_shifted_chebyshev_polynomial_w` | — | — |
| `special_sinc` | — | — |
| `special_softmax` | — | — |
| `special_spherical_bessel_j0` | — | — |
| `special_xlog1py` | — | 9 |
| `special_xlogy` | — | — |
| `special_zeta` | — | 9 |
| `split` | — | 2 |
| `split_copy` | — | — |
| `split_with_sizes` | ✅ | 4 |
| `split_with_sizes_copy` | — | 4 |
| `splitlines` | — | — |
| `sqrt` | ✅ | 1 |
| `sqrt_` | ✅ | — |
| `square` | ✅ | 3 |
| `square_` | ✅ | — |
| `squeeze` | ✅ | 8 |
| `squeeze_` | — | — |
| `squeeze_copy` | — | 8 |
| `sspaddmm` | — | — |
| `stack` | — | 9 |
| `startswith` | — | — |
| `std` | ✅ | 11 |
| `std_mean` | — | 11 |
| `stft` | — | 9 |
| `storage_offset` | — | — |
| `str` | — | — |
| `stride` | — | — |
| `strip` | — | — |
| `sub` | ✅ | 11 |
| `sub_` | ✅ | — |
| `subtract` | — | — |
| `subtract_` | — | — |
| `sum` | ✅ | 20 |
| `sum_to_size` | — | 16 |
| `svd` | — | 216 |
| `swapaxes` | — | — |
| `swapaxes_` | — | — |
| `swapcase` | — | — |
| `swapdims` | — | — |
| `swapdims_` | — | — |
| `sym_constrain_range` | — | — |
| `sym_constrain_range_for_size` | — | — |
| `sym_is_contiguous` | — | — |
| `sym_numel` | — | — |
| `sym_size` | — | — |
| `sym_storage_offset` | — | — |
| `sym_stride` | — | — |
| `t` | — | 3 |
| `t_` | — | — |
| `t_copy` | — | 3 |
| `take` | — | 10 |
| `take_along_dim` | — | 4 |
| `tan` | ✅ | 1 |
| `tan_` | ✅ | — |
| `tanh` | ✅ | 1 |
| `tanh_` | ✅ | — |
| `tanh_backward` | — | — |
| `tensor` | — | — |
| `tensor_split` | — | 10 |
| `tensordot` | — | 3 |
| `thnn_conv2d` | — | — |
| `threshold` | — | — |
| `threshold_` | — | — |
| `threshold_backward` | — | — |
| `tile` | — | 54 |
| `title` | — | — |
| `to` | — | 24 |
| `to_dense` | — | — |
| `to_dense_backward` | — | — |
| `to_here` | — | — |
| `to_mkldnn` | — | — |
| `to_mkldnn_backward` | — | — |
| `to_padded_tensor` | — | — |
| `to_sparse` | — | 2 |
| `to_sparse_bsc` | — | — |
| `to_sparse_bsr` | — | — |
| `to_sparse_csc` | — | — |
| `to_sparse_csr` | — | — |
| `topk` | — | 14 |
| `trace` | — | 1 |
| `trace_backward` | — | — |
| `transpose` | ✅ | 8 |
| `transpose_` | — | — |
| `transpose_copy` | — | 8 |
| `trapezoid` | — | 9 |
| `trapz` | — | 9 |
| `triangular_solve` | — | 16 |
| `tril` | — | 8 |
| `tril_` | — | — |
| `tril_indices` | — | 6 |
| `triplet_margin_loss` | — | — |
| `triu` | — | 8 |
| `triu_` | — | — |
| `triu_indices` | — | 6 |
| `true_divide` | — | 9 |
| `true_divide_` | — | — |
| `trunc` | ✅ | 1 |
| `trunc_` | ✅ | — |
| `type_as` | — | — |
| `unbind` | — | 6 |
| `unbind_copy` | — | 6 |
| `unflatten` | — | 10 |
| `unflatten_dense_tensors` | — | — |
| `unfold` | — | 22 |
| `unfold_backward` | — | — |
| `unfold_copy` | — | 22 |
| `uniform` | — | 3 |
| `uniform_` | — | — |
| `unique_consecutive` | — | 264 |
| `unique_dim` | — | — |
| `unique_dim_consecutive` | — | — |
| `unsafe_chunk` | — | 3 |
| `unsafe_split` | — | 2 |
| `unsafe_split_with_sizes` | — | — |
| `unsqueeze` | ✅ | 9 |
| `unsqueeze_` | — | — |
| `unsqueeze_copy` | — | 9 |
| `update` | — | — |
| `upper` | — | — |
| `upsample_bicubic2d` | — | — |
| `upsample_bicubic2d_backward` | — | — |
| `upsample_bilinear2d` | — | — |
| `upsample_bilinear2d_backward` | — | — |
| `upsample_linear1d` | — | — |
| `upsample_linear1d_backward` | — | — |
| `upsample_nearest1d` | — | — |
| `upsample_nearest1d_backward` | — | — |
| `upsample_nearest2d` | — | — |
| `upsample_nearest2d_backward` | — | — |
| `upsample_nearest3d` | — | — |
| `upsample_nearest3d_backward` | — | — |
| `upsample_trilinear3d` | — | — |
| `upsample_trilinear3d_backward` | — | — |
| `value_selecting_reduction_backward` | — | — |
| `values` | — | — |
| `values_copy` | — | — |
| `vander` | — | — |
| `var` | ✅ | 11 |
| `var_mean` | — | 11 |
| `vdot` | — | 1 |
| `view` | ✅ | 7 |
| `view_as` | — | 4 |
| `view_as_complex` | — | 1 |
| `view_as_complex_copy` | — | — |
| `view_as_real` | — | 2 |
| `view_as_real_copy` | — | — |
| `view_copy` | — | 7 |
| `vsplit` | — | 2 |
| `vstack` | — | 2 |
| `wait` | — | — |
| `warn` | — | — |
| `where` | ✅ | 6 |
| `xlogy` | ✅ | 9 |
| `xlogy_` | ✅ | — |
| `zero` | — | — |
| `zero_` | — | 3 |
| `zeros` | — | 2 |
| `zeros_like` | — | 7 |
| `zfill` | — | — |

## Summary
- total aten ops: 1714
- supported by codegen: 285 / 1714 (16.6 %)
- unsupported by codegen: 1429
